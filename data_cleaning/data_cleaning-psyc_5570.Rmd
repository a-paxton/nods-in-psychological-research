---
title: "Introduction to Data Cleaning with the `tidyverse`"
author: "A. Paxton (*University of Connecticut*)"
output:
  html_document:
    keep_md: yes
---

Data cleaning is a critical first step for working with many naturally occurring
datasets. Data cleaning (also known in as *data munging*) is an opportunity for
you to explore your data, identify systematic issues with specific variables,
address missing data, and generally ensure that your data are ready for analysis.

You may already be in the habit of inspecting your data with experimentally
derived datasets, as it's *always* a good habit to check out your data (no
matter their source) before working with them. However, it's a bit more
important (and, potentially, a bit trickier) when dealing with NODS, as you may
not entirely know what to expect in the NODS as you first begin using them
(e.g., reliability of the data logging or data collection, nature of the data
collection equipment).

In this tutorial, we will be using the `tidyverse` library in R to walk through
some data cleaning steps. Remember that every dataset is different, and the
steps that we will be presenting here are by no means comprehensive for every
project. It's also useful to note that there are many ways to clean your data,
including many functions in base R, but the Tidyverse is a suite of libraries
that is rapidly gaining popularity in the behavioral and cognitive sciences.

This tutorial is an expansion and refocusing of an earlier tutorial of mine
about [clustering in R](https://github.com/a-paxton/clustering-tutorial).

***

# Preliminaries

First, let's get ready for our analyses. We do this by clearing our workspace
and loading in the libraries we'll need. It's good to get in the habit of 
clearing your workspace from the start so that you don't accidentally have
clashes with unneeded variables or dataframes that could affect your results.

As with our other tutorials, we'll use a function here to check for all required
packages and---if necessary---install them before loading them. Implementing
this (or a similar) function is a helpful first step, especially if you plan on
sharing your code with other people.

```{r clear-workspace}

# clear the workspace (useful if we're not knitting)
rm(list=ls())

```

```{r function-check-for-packages, include=FALSE}

# make sure we can load packages 
# (thanks to https://gist.github.com/smithdanielle/9913897)
load_or_install_packages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, 
                     dependencies = TRUE,
                     repos="http://cloud.r-project.org/")
  sapply(pkg, require, character.only = TRUE)
}
```

```{r load-packages, message=FALSE, results="hide"}

# specify which packages we'll need
required_packages = c("tidyverse")

# install them (if necessary) and load them
load_or_install_packages(required_packages)

```

***

# Data preparation

***

## Load the data

Next, we'll load our data. For this first tutorial, we'll use a toy dataset
that's already included in R: `USArrests`. It includes arrest statistics for
U.S. states from 1973. This is a relatively simple naturally occurring dataset,
but it's fairly easy to work with because it's already in R.

```{r load-data}

# read in the dataset
arrest_df = USArrests

```

We gave our variable an informative name---here, `arrest_df`. A common
convention is to use `df` as an abbreviation for "dataframe," or a collection of
variables. It's good to get in the habit of giving your variables and dataframes
more informative names than a single letter (e.g., `x`, `a`) or generic names
(e.g., `dataframe`) so that you can remember what you're handling at any moment.

(And don't forget: Future You will thank Past You when you've made easily
understandable variable names, too, rather than cursing Past You for making
Future You go through all of the code to figure out what `this_variable` is
doing and why.)

## Visual inspection

A good first step is to check out your dataset after you load it. You can use
the `head()` function to just look at the first 6 records (or however many you'd
like to specify manually).

```{r head-function}

# inspect the first 5 records
head(arrest_df)

```

You can also choose to inspect the data manually using RStudio's data viewer.
You can use the `View()` function to call it programmatically, although you'll
note that nothing will pop up when we knit such a command.

```{r view-function}

# programmatically call the data viewer
View(arrest_df)

```

## Summary statistics

After our visual inspection, we might want to get a better feel for the
distributions of our data. We can use the `summary()` basic R commands to
understand all of our variables at a glance.

```{r create-summary}

# print summary statistics for all of our variables at once
summary(arrest_df)

```

While `summary()` is a great quick function for this, let's take a look at some
`tidy` alternatives and begin our introduction to the Tidyverse.

```{r tidy-summary}

arrest_df %>%
  summarize(min_murder = min(Murder),
            mean_murder = mean(Murder),
            max_murder = max(Murder))

```

Note that we're here using this symbol: `%>%`. This is called a "pipe" in the
Tidyverse. The Tidyverse is controversial: To some, it's a way of streamlining
sometimes complex code to make it more human-readable; to others, it's a
headache-inducing abomination. I admit that I fall into the former camp, but I
recognize that many folks---especially those who are more fond of Python than
R---hold the opposing opinion. However, even if you don't personally prefer this
style, it's useful for you to know how to read and interact with the Tidyverse,
since it's relatively common within the cognitive science and psychology
community.

The pipe allows you to pass the results of one function to another function
in the same chunk of code. It's like an assembly line, passing the dataframe
that you call in the first line (above, `arrest_df %>%`) to the next line
(above, `summarize(...)`). You can continue passing the results to additional
functions by continuing to pipe.

You might wonder why we're putting each function on a new line. Another good
habit for programmers---especially for programmers who use git as part of
their code-sharing or version control---is to keep your lines to 80 characters
or less. If you take a look at the `.Rmd` of this tutorial, you'll see that
I'm breaking the lines of text to be about 80 characters, too. This not only
helps your code be a bit more readable (rather than really long lines of code)
but also helps you see more easily the changes that have happened from version
to version in git.
