---
title: "Introduction to Regular Expressions in R"
author: "A. Paxton (*University of Connecticut*)"
output:
  html_document:
    keep_md: yes
---

*Regular expressions* (or *regex*) are sequences that permit pattern matching
and manipulation of substrings within strings. They are incredibly useful tools
for reproducibly working with well-defined units at scale. In other words, if
you want to identify and remove any pesky HTML tags that snuck into your scraped
dataset, you could scroll through a `.txt` or `.csv` file in a text editor and then
manually delete them, but that would take a *very* long time and could result in
human error. (And what would happen if you wanted to expand your dataset or if
your dataset needed to be re-scraped? Despair!)

In this tutorial, we will be using the `stringr` library in R to learn some
regular expressions using data from [ProPublica's Congress
API](https://projects.propublica.org/api-docs/congress-api/). You can request an
API key from their [Data
Store](https://www.propublica.org/datastore/apirequest). Assuming your file
structure mirrors the file structure of this repository, you should save the API
key as a single line in a text file named `propublica_key.txt` in the
`nods-in-psychological-research` directory (one level above the one in which
this `.Rmd` is saved). We will use the `ProPublicaR` library to grab the data.

Part of the ProPublica API's terms of service include that the data won't be
shared, so I will not be showing raw output in chunks. You can change the chunks
to remove `results="hide"` from the options when you run the code locally.

To help with this tutorial, check out these wonderful cheat sheets:
* For `stringr`: https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf
* For base R: https://rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf

***

# Preliminaries

First, let's get ready for our analyses. We do this by clearing our workspace
and loading in the libraries we'll need. It's good to get in the habit of 
clearing your workspace from the start so that you don't accidentally have
clashes with unneeded variables or dataframes that could affect your results.

As with our other tutorials, we'll use a function here to check for all required
packages and---if necessary---install them before loading them. Implementing
this (or a similar) function is a helpful first step, especially if you plan on
sharing your code with other people.

```{r clear-workspace}

# clear the workspace (useful if we're not knitting)
rm(list=ls())

```

```{r function-check-for-packages, include=FALSE}

# make sure we can load packages 
# (thanks to https://gist.github.com/smithdanielle/9913897)
load_or_install_packages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, 
                     dependencies = TRUE,
                     repos="http://cloud.r-project.org/")
  sapply(pkg, require, character.only = TRUE)
}
```

```{r load-packages, message=FALSE, results="hide"}

# specify which packages we'll need
required_packages = c("tidyverse",
                      "stringr",
                      "readr",
                      "data.table",
                      "ProPublicaR")

# install them (if necessary) and load them
load_or_install_packages(required_packages)

```

***

# Data preparation

***

## Specify our API key

In order to use the `ProPublicaR` package to access the data, we need to loading
in our ProPublica Congressional API key.

```{r load-key}

# read in the API key
propublica_key = read_file("../propublica_key.txt")

```

In your console (or by adding a new chunk in your R markdown), take a look at
your API key. You should see the long alphanumeric string that you received from
ProPublica---but you may also have two new characters at the end: `\n`. That's
an invisible character that indicates a new line. As our first regular expression,
let's go ahead and remove it.

We'll do this by using `stringr::str_remove()`, a function that will remove any
substring that matches our predefined pattern from the longer string. In our
case, our `string` is `propublica_key`, and our `pattern` is our newline
character, `\n`.

```{r remove-newline}

# remove the newline from the API key
propublica_key = str_remove(propublica_key, "\n")

```

Take a look at your key again in your console. If you had the `\n` in your key
initially, you should see that it's now gone. Congrats! You just used your first
(maybe) regular expression.

One important lesson that this teaches us is that regex doesn't just deal with
the characters that we can see when we open a text file. It's much more powerful
than that: It can handle invisible characters that specify things behind the
scenes, from newlines to the beginning or end of a string.

## Load the data

Now that we've got our API key working, let's plug it into the
`get_recent_congressional_statements()` function to grab the 20 most recent
statements from U.S. Congressmembers.

```{r load-recent-statements}

# get the most recent Congressional statements
recent_statements = get_recent_congressional_statements(page = 1, 
                                                        propublica_key)

# convert to dataframe
recent_statements_df = rbindlist(recent_statements$results,
                                 fill = TRUE)

```

***

# Data processing

***

Now, let's play around with some regular expressions. First, let's have a look
at our data. (Because---remember---we always, always, always look at our data.)

```{r examine-data, results="hide"}

# let's take a peek
head(recent_statements_df)

```

Okay, so we've got a variety of different kinds of data here. Great for
practicing!

## Identifying substrings

First, let's work to identify a substring. Let's say we want to find all
statements with a title that includes the word "Congress" in it. We'll use the
`stringr::str_detect()` function to produce a logical vector of whether our
input vector's items include our target pattern. In this case, our `string` is
`recent_statements_df$title`, and our pattern is `Congress`.

```{r identify-titles-with-congress}

# create a new column that specifies whether the statement title mentions Congress
recent_statements_df$title_mentions_congress = str_detect(
  string=recent_statements_df$title,
  pattern="Congress")

# let's see what we got
recent_statements_df$title_mentions_congress

```

We could, if we wanted, then use this vector to analyze differences between,
say, statements that mention Congress by name and those that don't.

But, hmm... that doesn't look right. There should be more than this. Let's
look at the raw titles.

```{r show-titles, results = "hide"}

# let's look at the raw titles
recent_statements_df$title

```
Ah, it seems like there's a problem with capitalization. Let's handle the
capitalization issue and then try to identify them again. We can do this all at
once with `stringr::str_to_lower()`. But remember, we'll *also* have to change
the `pattern` to be lowercase, or we won't be able to find the `Congress`
substring within our text.

```{r lowercase-titles-then-identify-congress}

# create a new variable that converts the title to lowercase
recent_statements_df$title_lower = str_to_lower(recent_statements_df$title)

# revise the Congress identification column
recent_statements_df$title_mentions_congress = str_detect(
  string=recent_statements_df$title_lower,
  pattern="congress")

# let's check out our new results
recent_statements_df$title_mentions_congress

```

Much better!

## Swapping substrings

Let's try swapping substrings now. Let's say that we regret our decision to
convert everything to lowercase and want "Congress" to be capitalized. We can do
that with `stringr::str_replace_all()`. Our `string` is our new lowercase title
variable, `recent_statements_df$title_lower`, our `pattern` is `congress`, and
our `replacement` is `Congress`.

```{r swap-out-congress}

# re-capitalize Congress
recent_statements_df$title_capital_congress = str_replace_all(
  string = recent_statements_df$title_lower,
  pattern = "congress",
  replacement = "Congress"
)

```

Now, let's see if it worked. We can do this by counting the number of times that
`congress` and `Congress` appeared in our transformed title variable.

```{r check-swap-efficacy}

# and let's see whether it worked: how many "congress" appearances?
sum(
  str_count(
  string=recent_statements_df$title_capital_congress,
  pattern="congress")
)

# and let's see whether it worked: how many "Congress" appearances?
sum(
  str_count(
  string=recent_statements_df$title_capital_congress,
  pattern="Congress")
)

```

It worked!